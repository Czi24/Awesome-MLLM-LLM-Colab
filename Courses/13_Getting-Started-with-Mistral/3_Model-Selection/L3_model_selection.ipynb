{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f501ffce-f4f6-4701-8dd3-3ed32a5134ba",
   "metadata": {},
   "source": [
    "# Model Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd845946-a8c7-4e06-9ffe-dd893ee5e137",
   "metadata": {},
   "source": [
    "### Get API Key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4896b6d5-9e73-4fd1-9fc0-8a7cb93bb750",
   "metadata": {
    "height": 46
   },
   "outputs": [],
   "source": [
    "from helper import load_mistral_api_key\n",
    "api_key, dlai_endpoint = load_mistral_api_key(ret_key=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5800f02-c8a0-4e82-a4bd-ce6ddf7a26b7",
   "metadata": {},
   "source": [
    "- Note: in the classroom, if you print out this `api_key` variable, it is not a real API key (for security reasons).\n",
    "- If you wish to run this code on your own machine, outside of the classroom, you can still reuse the code that you see in `helper.py`.\n",
    "- It uses [python-dotenv](https://pypi.org/project/python-dotenv/) library to securely save and load sensitive information such as API keys."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51403fae-91e9-4e24-9353-02495cb2babc",
   "metadata": {
    "height": 301
   },
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai.client import MistralClient\n",
    "from mistralai.models.chat_completion import ChatMessage\n",
    "\n",
    "def mistral(user_message, model=\"mistral-small-latest\", is_json=False):\n",
    "    client = MistralClient(api_key=api_key, endpoint=dlai_endpoint)\n",
    "    messages = [ChatMessage(role=\"user\", content=user_message)]\n",
    "\n",
    "    if is_json:\n",
    "        chat_response = client.chat(\n",
    "            model=model, messages=messages, response_format={\"type\": \"json_object\"}\n",
    "        )\n",
    "    else:\n",
    "        chat_response = client.chat(model=model, messages=messages)\n",
    "\n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "03db3133-63d2-4cc7-b562-efce0991a143",
   "metadata": {},
   "source": [
    "## Mistral Small\n",
    "\n",
    "Good for simple tasks, fast inference, lower cost.\n",
    "- classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18eaa6a5-6653-4587-8077-e409191c790b",
   "metadata": {
    "height": 165
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Classify the following email to determine if it is spam or not.\n",
    "Only respond with the exact text \"Spam\" or \"Not Spam\". \n",
    "\n",
    "# Email:\n",
    "ðŸŽ‰ Urgent! You've Won a $1,000,000 Cash Prize! \n",
    "ðŸ’° To claim your prize, please click on the link below: \n",
    "https://bit.ly/claim-your-prize\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11cef6cd-bb24-46c5-9e83-2d81168057eb",
   "metadata": {
    "height": 29,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mistral(prompt, model=\"mistral-small-latest\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ac31f9e-8446-417c-aec8-598e141686bc",
   "metadata": {},
   "source": [
    "## Mistral Medium\n",
    "\n",
    "Good for intermediate tasks such as language transformation.\n",
    "- Composing text based on provided context (e.g. writing a customer service email based on purchase information)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ce9677-a0a2-40ef-903d-571561c0fc65",
   "metadata": {
    "height": 250
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Compose a welcome email for new customers who have just made \n",
    "their first purchase with your product. \n",
    "Start by expressing your gratitude for their business, \n",
    "and then convey your excitement for having them as a customer. \n",
    "Include relevant details about their recent order. \n",
    "Sign the email with \"The Fun Shop Team\".\n",
    "\n",
    "Order details:\n",
    "- Customer name: Anna\n",
    "- Product: hat \n",
    "- Estimate date of delivery: Feb. 25, 2024\n",
    "- Return policy: 30 days\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0bb8a6-5be9-4a83-9413-14e154c845de",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "response_medium = mistral(prompt, model=\"mistral-medium-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6de3dada-f0e1-4dee-9a41-31cac83256b0",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "print(response_medium)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3b2c99-c01a-4beb-8685-355f6c21ce55",
   "metadata": {},
   "source": [
    "## Mistral Large: \n",
    "\n",
    "Good for complex tasks that require advanced reasoning.\n",
    "- Math and reasoning with numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc4c9957-48dc-46b8-bb6f-f506af1f768f",
   "metadata": {
    "height": 267
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Calculate the difference in payment dates between the two \\\n",
    "customers whose payment amounts are closest to each other \\\n",
    "in the following dataset. Do not write code.\n",
    "\n",
    "# dataset: \n",
    "'{\n",
    "  \"transaction_id\":{\"0\":\"T1001\",\"1\":\"T1002\",\"2\":\"T1003\",\"3\":\"T1004\",\"4\":\"T1005\"},\n",
    "    \"customer_id\":{\"0\":\"C001\",\"1\":\"C002\",\"2\":\"C003\",\"3\":\"C002\",\"4\":\"C001\"},\n",
    "    \"payment_amount\":{\"0\":125.5,\"1\":89.99,\"2\":120.0,\"3\":54.3,\"4\":210.2},\n",
    "\"payment_date\":{\"0\":\"2021-10-05\",\"1\":\"2021-10-06\",\"2\":\"2021-10-07\",\"3\":\"2021-10-05\",\"4\":\"2021-10-08\"},\n",
    "    \"payment_status\":{\"0\":\"Paid\",\"1\":\"Unpaid\",\"2\":\"Paid\",\"3\":\"Paid\",\"4\":\"Pending\"}\n",
    "}'\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba02ea8b-8872-4a7d-8195-6285e4b422a3",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "response_small = mistral(prompt, model=\"mistral-small-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74554e58-25a0-402d-95ad-8ada5c0cc743",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "print(response_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "987a0aef-67dc-4ada-82ac-4b0dc1b6b5ae",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "response_large = mistral(prompt, model=\"mistral-large-latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21a55c1-c700-4bf3-be22-5ad432dc3f10",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "print(response_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a15be44d-ecb4-47f6-bed5-5b08c6bc391a",
   "metadata": {},
   "source": [
    "## Expense reporting task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7c1deb9-37f4-4182-b43c-3bad2637598c",
   "metadata": {
    "height": 352
   },
   "outputs": [],
   "source": [
    "transactions = \"\"\"\n",
    "McDonald's: 8.40\n",
    "Safeway: 10.30\n",
    "Carrefour: 15.00\n",
    "Toys R Us: 20.50\n",
    "Panda Express: 10.20\n",
    "Beanie Baby Outlet: 25.60\n",
    "World Food Wraps: 22.70\n",
    "Stuffed Animals Shop: 45.10\n",
    "Sanrio Store: 85.70\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "Given the purchase details, how much did I spend on each category:\n",
    "1) restaurants\n",
    "2) groceries\n",
    "3) stuffed animals and props\n",
    "{transactions}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c534c567-cd20-4abb-adbc-cc9fe919c2f8",
   "metadata": {
    "height": 46
   },
   "outputs": [],
   "source": [
    "response_small = mistral(prompt, model=\"mistral-small-latest\")\n",
    "print(response_small)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47960a78-7689-47ee-adee-6c8412d5477b",
   "metadata": {
    "height": 46
   },
   "outputs": [],
   "source": [
    "response_large = mistral(prompt, model=\"mistral-large-latest\")\n",
    "print(response_large)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f90d6068-61b3-4490-aeb4-0be67ba9fd1b",
   "metadata": {},
   "source": [
    "## Writing and checking code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27945975-d2bc-40b9-9a59-48b10fe4da4b",
   "metadata": {
    "height": 250
   },
   "outputs": [],
   "source": [
    "user_message = \"\"\"\n",
    "Given an array of integers nums and an integer target, return indices of the two numbers such that they add up to target.\n",
    "\n",
    "You may assume that each input would have exactly one solution, and you may not use the same element twice.\n",
    "\n",
    "You can return the answer in any order.\n",
    "\n",
    "Your code should pass these tests:\n",
    "\n",
    "assert twoSum([2,7,11,15], 9) == [0,1]\n",
    "assert twoSum([3,2,4], 6) == [1,2]\n",
    "assert twoSum([3,3], 6) == [0,1]\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e00a7bc-069a-43f9-bb02-e33a5d3dcc2f",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": [
    "print(mistral(user_message, model=\"mistral-large-latest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e007ef-17fb-450a-85d5-f456d06352e1",
   "metadata": {},
   "source": [
    "### Try out the code that the model provided\n",
    "- Copy the code that the model provided and try running it!\n",
    "\n",
    "Here is the code that was output at the time of filming:\n",
    "```Python\n",
    "def twoSum(nums, target):\n",
    "    seen = {}\n",
    "    for i, num in enumerate(nums):\n",
    "        complement = target - num\n",
    "        if complement in seen:\n",
    "            return [seen[complement], i]\n",
    "        seen[num] = i\n",
    "```\n",
    "- Also try running the assert statements in the original prompt\n",
    "```Python\n",
    "assert twoSum([2,7,11,15], 9) == [0,1]\n",
    "assert twoSum([3,2,4], 6) == [1,2]\n",
    "assert twoSum([3,3], 6) == [0,1]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd58acf-fa92-431d-a08a-ce05c1e21003",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49638589-88c6-439c-8192-65c511522fc1",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3db8aa2a-aa1f-45f1-b4a4-d8eedc927677",
   "metadata": {},
   "source": [
    "## Natively Fluent in English, French, Spanish, German, and Italian\n",
    "- This means that you can use Mistral models for more than translating from one language to another.\n",
    "- If you are a native Spanish speaker, for instance, you can communicate with Mistral models in Spanish for any of your tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cbad716-8da8-4c00-8eb1-889b69567986",
   "metadata": {
    "height": 80
   },
   "outputs": [],
   "source": [
    "user_message = \"\"\"\n",
    "Lequel est le plus lourd une livre de fer ou un kilogramme de plume\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72722d49-b12b-4334-bc1c-318874c57959",
   "metadata": {
    "height": 29,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(mistral(user_message, model=\"mistral-large-latest\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd4f1e52-49d5-4d02-b85c-5bce23896a20",
   "metadata": {},
   "source": [
    "### Try it out for yourself\n",
    "- Try communicating with the Mistral Large model in Spanish\n",
    "  - (If you need help, you can first translate a prompt from English to Spanish, and then prompt the model in Spanish)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc301515-157c-450b-828e-554ee6760809",
   "metadata": {},
   "source": [
    "## List of Mistral models that you can call:\n",
    "\n",
    "You can also call the two open source mistral models via API calls.\n",
    "Here is the list of models that you can try:\n",
    "```\n",
    "open-mistral-7b\n",
    "open-mixtral-8x7b\n",
    "open-mixtral-8x22b\n",
    "mistral-small-latest\n",
    "mistral-medium-latest\n",
    "mistral-large-latest\n",
    "```\n",
    "\n",
    "For example:\n",
    "```Python\n",
    "mistral(prompt, model=\"open-mixtral-8x22b\")\n",
    "```\n",
    "\n",
    "Note that we just released the `open-mixtral-8x22b` model. Check out our [release blog](https://mistral.ai/news/mixtral-8x22b/) for details. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e316a8f-57fc-4774-980e-118c01239636",
   "metadata": {
    "height": 29
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
