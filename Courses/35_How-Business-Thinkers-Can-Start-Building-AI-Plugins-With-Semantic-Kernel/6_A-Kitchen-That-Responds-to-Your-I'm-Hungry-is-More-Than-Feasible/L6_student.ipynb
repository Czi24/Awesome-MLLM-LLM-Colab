{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🧑‍🍳 L6 - A kitchen that responds to your “I’m hungry” is more than feasible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inventory:\n",
    "\n",
    "1. Kernel\n",
    "2. Semantic (and Native) functions -- you can do a lot with these\n",
    "3. BusinessThinking plugin --> SWOTs in ways you could never imagine\n",
    "4. DesignThinking plugin --> you did that. Congrats\n",
    "5. Use the similarity engine to your heart's content 🧲\n",
    "6. THE BIG ONE!!!!!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔥 Let's make a kernel one more time!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 319
   },
   "outputs": [],
   "source": [
    "import semantic_kernel as sk\n",
    "from semantic_kernel.connectors.ai.open_ai import OpenAIChatCompletion, OpenAITextEmbedding\n",
    "from semantic_kernel.connectors.ai.open_ai import AzureChatCompletion, AzureTextEmbedding\n",
    "from IPython.display import display, Markdown\n",
    "\n",
    "kernel = sk.Kernel()\n",
    "\n",
    "useAzureOpenAI = False\n",
    "\n",
    "if useAzureOpenAI:\n",
    "    deployment, api_key, endpoint = sk.azure_openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"azureopenaicompletion\", AzureChatCompletion(deployment, endpoint, api_key))\n",
    "    kernel.add_text_embedding_generation_service(\"azureopenaiembedding\", AzureTextEmbedding(\"text-embedding-ada-002\", api_key, endpoint))\n",
    "else:\n",
    "    api_key, org_id = sk.openai_settings_from_dot_env()\n",
    "    kernel.add_text_completion_service(\"openaicompletion\", OpenAIChatCompletion(\"gpt-3.5-turbo-0301\", api_key, org_id))\n",
    "    kernel.add_text_embedding_generation_service(\"openaiembedding\", OpenAITextEmbedding(\"text-embedding-ada-002\", api_key, org_id))\n",
    "print(\"I did it boss!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to have a vat of plugins ... and then find the right plugin to fit the goal ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: You can find more about the predefined plugins used below [here](https://learn.microsoft.com/en-us/semantic-kernel/ai-orchestration/out-of-the-box-plugins?tabs=Csharp)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import ActionPlanner\n",
    "\n",
    "planner = ActionPlanner(kernel)\n",
    "\n",
    "from semantic_kernel.core_skills import FileIOSkill, MathSkill, TextSkill, TimeSkill\n",
    "kernel.import_skill(MathSkill(), \"math\")\n",
    "kernel.import_skill(FileIOSkill(), \"fileIO\")\n",
    "kernel.import_skill(TimeSkill(), \"time\")\n",
    "kernel.import_skill(TextSkill(), \"text\")\n",
    "\n",
    "print(\"Adding the tools for the kernel to do math, to read/write files, to tell the time, and to play with text.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "ask = \"What is the sum of 110 and 990?\"\n",
    "\n",
    "print(f\"🧲 Finding the most similar function available to get that done...\")\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "print(f\"🧲 The best single function to use is `{plan._skill_name}.{plan._function.name}`\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "ask = \"What is today?\"\n",
    "print(f\"🧲 Finding the most similar function available to get that done...\")\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "print(f\"🧲 The best single function to use is `{plan._skill_name}.{plan._function.name}`\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "ask = \"How do I write the word 'text' to a file?\"\n",
    "print(f\"🧲 Finding the most similar function available to get that done...\")\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "print(f\"🧲 The best single function to use is `{plan._skill_name}.{plan._function.name}`\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Note**: The next two cells will *sometimes return an error*. The LLM response is variable and at times can't be successfully parsed by the planner or the LLM will make up new functions.  If this happens, try resetting the jupyter notebook kernel and running it again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 455
   },
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "from semantic_kernel.planning.sequential_planner.sequential_planner_config import SequentialPlannerConfig\n",
    "\n",
    "plugins_directory = \"./plugins-sk\"\n",
    "writer_plugin = kernel.import_semantic_skill_from_directory(plugins_directory, \"LiterateFriend\")\n",
    "\n",
    "# create an instance of sequential planner, and exclude the TextSkill from the list of functions that it can use.\n",
    "# (excluding functions that ActionPlanner imports to the kernel instance above - it uses 'this' as skillName)\n",
    "planner = SequentialPlanner(kernel, SequentialPlannerConfig(excluded_skills=[\"this\"]))\n",
    "\n",
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a poem. Translate the poem to French.\n",
    "\"\"\"\n",
    "\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(f\"✅ Step {index+1} used function `{step._function.name}`\")\n",
    "\n",
    "trace_resultp = True\n",
    "\n",
    "display(Markdown(f\"## ✨ Generated result from the ask: {ask}\\n\\n---\\n\" + str(result)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add tracing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 608
   },
   "outputs": [],
   "source": [
    "from semantic_kernel.planning import SequentialPlanner\n",
    "from semantic_kernel.core_skills.text_skill import TextSkill\n",
    "from semantic_kernel.planning.sequential_planner.sequential_planner_config import SequentialPlannerConfig\n",
    "\n",
    "plugins_directory = \"./plugins-sk\"\n",
    "writer_plugin = kernel.import_semantic_skill_from_directory(plugins_directory, \"LiterateFriend\")\n",
    "\n",
    "planner = SequentialPlanner(kernel, SequentialPlannerConfig(excluded_skills=[\"this\"]))\n",
    "\n",
    "ask = \"\"\"\n",
    "Tomorrow is Valentine's day. I need to come up with a poem. Translate the poem to French.\n",
    "\"\"\"\n",
    "\n",
    "plan = await planner.create_plan_async(goal=ask)\n",
    "planner = SequentialPlanner(kernel, SequentialPlannerConfig(excluded_skills=[\"this\"]))\n",
    "result = await plan.invoke_async()\n",
    "\n",
    "for index, step in enumerate(plan._steps):\n",
    "    print(f\"✅ Step {index+1} used function `{step._function.name}`\")\n",
    "\n",
    "trace_resultp = True\n",
    "\n",
    "if trace_resultp:\n",
    "    print(\"Longform trace:\\n\")\n",
    "    for index, step in enumerate(plan._steps):\n",
    "        print(\"Step:\", index)\n",
    "        print(\"Description:\",step.description)\n",
    "        print(\"Function:\", step.skill_name + \".\" + step._function.name)\n",
    "        print(\"Input vars:\", step._parameters._variables)\n",
    "        print(\"Output vars:\", step._outputs)\n",
    "        if len(step._outputs) > 0:\n",
    "            print( \"  Output:\\n\", str.replace(result[step._outputs[0]],\"\\n\", \"\\n  \"))\n",
    "\n",
    "display(Markdown(f\"## ✨ Generated result from the ask: {ask}\\n\\n---\\n\" + str(result)))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 🔖 There are a variety of limitations to using the planner in August of 2023 in terms of number of tokens required and model preference that we can expect to slowly vanish over time. For simple tasks, this Planner-based approach is unusually powerful. It takes full advantage of both COMPLETION and SIMILARITY in a truly magical way.\n",
    "\n",
    "![](./assets/twodimensions.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "height": 30
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
